{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python3\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk as nltk\n",
    "import spacy\n",
    "import regex\n",
    "import re\n",
    "import sklearn\n",
    "from nltk import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df[['uuid','postText','targetParagraphs']]\n",
    "\n",
    "    # convert all columns into strings\n",
    "    df[['postText', 'targetParagraphs']] = df[['postText', 'targetParagraphs']].astype(str)\n",
    "    #tokenize the relevant columns (not actually used for the Bag of Word approach)\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    df[\"postText_tokens\"] = df.apply(lambda row: tokenizer.tokenize(row[\"postText\"]), axis = 1)\n",
    "    df[\"paragraph_tokens\"] = df.apply(lambda row: tokenizer.tokenize(row[\"targetParagraphs\"]), axis = 1)\n",
    "\n",
    "    #removing stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    df[\"postText_tokens\"] = df.apply(lambda row: [element for element in row[\"postText_tokens\"] if element not in stopwords], axis = 1)\n",
    "    df[\"paragraph_tokens\"] = df.apply(lambda row: [element for element in row[\"paragraph_tokens\"] if element not in stopwords], axis = 1)\n",
    "    \n",
    "    #lowercasing \n",
    "    df['postText_tokens'] = df['postText_tokens'].map(lambda row: list(map(str.lower, row)))\n",
    "    df['paragraph_tokens'] = df['paragraph_tokens'].map(lambda row: list(map(str.lower, row)))\n",
    "    \n",
    "    # multiple space to single space\n",
    "    df[['postText_tokens', 'paragraph_tokens']] = df[['postText_tokens', 'paragraph_tokens']].replace(r'\\s+', ' ', regex=True)\n",
    "    #special characters\n",
    "    df[['postText_tokens', 'paragraph_tokens']] = df[['postText_tokens', 'paragraph_tokens']].replace(r'\\W', ' ', regex = True)\n",
    "\n",
    "    #lemmatize tokens\n",
    "    df['postText_tokens'] = df['postText_tokens'].apply(lemmatize_text)\n",
    "    df['paragraph_tokens'] = df['paragraph_tokens'].apply(lemmatize_text)\n",
    "\n",
    "    #count column lengths\n",
    "    df['postText_length'] = \"\"\n",
    "    df['paragraph_length'] = \"\"\n",
    "    for i in range(len(df)):\n",
    "        df['postText_length'][i] = len(df['postText_tokens'][i])\n",
    "        df['paragraph_length'][i] = len(df['paragraph_tokens'][i])\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        questionmark = \"?\"\n",
    "        df['has_questionmark'] = 'posthasquestionmark'\n",
    "        if questionmark in df['postText'][i]:\n",
    "            df['has_questionmark'] = 'posthasnoquestionmark'\n",
    "            \n",
    "            \n",
    "    mean_postText_length = df['postText_length'].mean()\n",
    "    mean_paragraph_length = df['paragraph_length'].mean()\n",
    "\n",
    "    df['postText_length'] = df['postText_length'].apply(lambda x: 'overavg_post_length' if x > mean_postText_length else 'underavg_post_length')\n",
    "    df['paragraph_length'] = df['paragraph_length'].apply(lambda x: 'overavg_paragraph_length' if x > mean_paragraph_length else 'underavg_paragraph_length')\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        df['has_numeric'] = any(str.isdigit(c) for c in df['targetParagraphs'][i])\n",
    "    df['has_numeric'] = np.where(df['has_numeric'], 'hasnumeric', 'nonumeric')\n",
    "   \n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    df['Entities'] = df['postText'].apply(lambda sent: [(ent.text, ent.label_) for ent in nlp(sent).ents])  \n",
    "    df['Entities'][0]\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tostring = str(df['Entities'][i])\n",
    "        tostring = ' '.join(str(item) for tup in df['Entities'][i] for item in tup)\n",
    "        df['Entities'][i] = tostring\n",
    "  \n",
    "    df['multi_signs'] = \"\"\n",
    "    multi_signs = ['1.', '2.', '3.', '4.', '5.', '6.','7.', '8,', '9.', '10', 'first', 'second', 'third', 'list']\n",
    "    df['multi_signs'] = df['targetParagraphs'].apply(lambda x: any([k in x for k in multi_signs]))\n",
    "\n",
    "    df['combined_texts'] = \"\"\n",
    "    df['combined_texts'] = df['postText'] + \" \" + df['targetParagraphs'] + \" \" + df['postText_length'] + \" \" + df['paragraph_length'] + \" \" + df['has_questionmark'] + \" \" + df['has_numeric'] + df['Entities']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"../Data/webis-clickbait-22/validation.jsonl\"\n",
    "df = pd.read_json(train_data_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasrehbach/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"postText_tokens\"] = df.apply(lambda row: tokenizer.tokenize(row[\"postText\"]), axis = 1)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"paragraph_tokens\"] = df.apply(lambda row: tokenizer.tokenize(row[\"targetParagraphs\"]), axis = 1)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"postText_tokens\"] = df.apply(lambda row: [element for element in row[\"postText_tokens\"] if element not in stopwords], axis = 1)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"paragraph_tokens\"] = df.apply(lambda row: [element for element in row[\"paragraph_tokens\"] if element not in stopwords], axis = 1)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['postText_tokens'] = df['postText_tokens'].map(lambda row: list(map(str.lower, row)))\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['paragraph_tokens'] = df['paragraph_tokens'].map(lambda row: list(map(str.lower, row)))\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['postText_tokens'] = df['postText_tokens'].apply(lemmatize_text)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['paragraph_tokens'] = df['paragraph_tokens'].apply(lemmatize_text)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['postText_length'] = \"\"\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['paragraph_length'] = \"\"\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['postText_length'][i] = len(df['postText_tokens'][i])\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['paragraph_length'][i] = len(df['paragraph_tokens'][i])\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['has_questionmark'] = 'posthasquestionmark'\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['has_questionmark'] = 'posthasnoquestionmark'\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['postText_length'] = df['postText_length'].apply(lambda x: 'overavg_post_length' if x > mean_postText_length else 'underavg_post_length')\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['paragraph_length'] = df['paragraph_length'].apply(lambda x: 'overavg_paragraph_length' if x > mean_paragraph_length else 'underavg_paragraph_length')\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['has_numeric'] = any(str.isdigit(c) for c in df['targetParagraphs'][i])\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['has_numeric'] = np.where(df['has_numeric'], 'hasnumeric', 'nonumeric')\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Entities'] = df['postText'].apply(lambda sent: [(ent.text, ent.label_) for ent in nlp(sent).ents])\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Entities'][i] = tostring\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['multi_signs'] = \"\"\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['multi_signs'] = df['targetParagraphs'].apply(lambda x: any([k in x for k in multi_signs]))\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['combined_texts'] = \"\"\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/3948839533.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['combined_texts'] = df['postText'] + \" \" + df['targetParagraphs'] + \" \" + df['postText_length'] + \" \" + df['paragraph_length'] + \" \" + df['has_questionmark'] + \" \" + df['has_numeric'] + df['Entities']\n"
     ]
    }
   ],
   "source": [
    "data = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "    vectorizer = CountVectorizer(stop_words=stopwords, lowercase=True, tokenizer = tokenizer.tokenize, ngram_range=(1,1))\n",
    "    combined_bow = vectorizer.fit_transform(df['combined_texts']).toarray()\n",
    "    bag_of_words = pd.DataFrame(combined_bow, columns=vectorizer.get_feature_names())\n",
    "\n",
    "    tfidfconverter = TfidfTransformer()\n",
    "    combined_bow = tfidfconverter.fit_transform(combined_bow).toarray()\n",
    "    combined_bow = pd.DataFrame(combined_bow)\n",
    "    return combined_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27347</th>\n",
       "      <th>27348</th>\n",
       "      <th>27349</th>\n",
       "      <th>27350</th>\n",
       "      <th>27351</th>\n",
       "      <th>27352</th>\n",
       "      <th>27353</th>\n",
       "      <th>27354</th>\n",
       "      <th>27355</th>\n",
       "      <th>27356</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 27357 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1      2      3      4      5      6      7      8      9      \\\n",
       "0      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "795    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "796    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "797    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "798    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "799    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "     ...  27347  27348  27349  27350     27351  27352  27353  27354  27355  \\\n",
       "0    ...    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0   \n",
       "1    ...    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0   \n",
       "2    ...    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0   \n",
       "3    ...    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0   \n",
       "4    ...    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0   \n",
       "..   ...    ...    ...    ...    ...       ...    ...    ...    ...    ...   \n",
       "795  ...    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0   \n",
       "796  ...    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0   \n",
       "797  ...    0.0    0.0    0.0    0.0  0.114082    0.0    0.0    0.0    0.0   \n",
       "798  ...    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0   \n",
       "799  ...    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0   \n",
       "\n",
       "     27356  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "..     ...  \n",
       "795    0.0  \n",
       "796    0.0  \n",
       "797    0.0  \n",
       "798    0.0  \n",
       "799    0.0  \n",
       "\n",
       "[800 rows x 27357 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    pickled_LR_Model = pickle.load(open(\"Pickle_LR_Model.pkl\", \"rb\"))\n",
    "    return pickled_LR_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_type(df):\n",
    "    model = getModel()\n",
    "    data = transform_data(df)\n",
    "    dummy_df = pd.DataFrame(0, index=data.index, columns=range(62332-data.shape[1]))\n",
    "    merged_df = pd.concat([data, dummy_df], axis=1)\n",
    "    prediction = model.predict(merged_df)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_type(data)\n",
    "prediction = pd.DataFrame(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    2\n",
       "1    2\n",
       "2    1\n",
       "3    1\n",
       "4    2\n",
       "..  ..\n",
       "795  2\n",
       "796  2\n",
       "797  2\n",
       "798  2\n",
       "799  2\n",
       "\n",
       "[800 rows x 1 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid = data[['uuid', 'postText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_622/366263583.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uuid['prediction'] = prediction\n"
     ]
    }
   ],
   "source": [
    "uuid['prediction'] = prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    591\n",
       "1    209\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid.prediction.value_counts()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "360b179fdceef7742b76a361c16c815382f1d581b7002dc53198cac855f64a5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
