{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bedfabe",
   "metadata": {},
   "source": [
    "# Working on the question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2eedab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57700097",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"Data/webis-clickbait-22/train.jsonl\"\n",
    "df = pd.read_json(train_data_path, lines=True)\n",
    "\n",
    "df_selected = df[['postText','targetParagraphs', 'spoiler', 'postPlatform', 'tags']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc5e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "203db7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.8244224190711975, 'start': 1251, 'end': 1258, 'answer': 'Stories'} \n",
      " \n",
      " \"the feature that allowed you to see a map of where a given users photos were taken (if they designated a location for the photo).\"\n",
      "{'score': 0.0003152992285322398, 'start': 307, 'end': 327, 'answer': 'should we be worried'} \n",
      " \n",
      " scientists didnâ€™t find pathogenic organisms that typically cause sickness or antibiotic-resistant genes\n",
      "{'score': 0.01897354982793331, 'start': 1358, 'end': 1419, 'answer': 'none of this explains the sheer numbers of the Weasley family'} \n",
      " \n",
      " because of the war with Voldemort.\n",
      "{'score': 0.16883143782615662, 'start': 1177, 'end': 1178, 'answer': '.'} \n",
      " \n",
      " just that famous VW badge ... ... which flips open when the car is in reverse to reveal the hidden camera!\n",
      "{'score': 0.0011867046123370528, 'start': 839, 'end': 863, 'answer': 'Macarena has a boyfriend'} \n",
      " \n",
      " \"Macarena\" is about a woman who waits until her boyfriend leaves town and then bangs his two best friends at the same time.\n",
      "{'score': 0.0036445753648877144, 'start': 2, 'end': 90, 'answer': 'Authorities have uncovered human remains during their search for a missing Virginia teen'} \n",
      " \n",
      " Southampton County, \"Anjelica AJ Hadsell\"\n",
      "{'score': 0.00010872145503526554, 'start': 575, 'end': 607, 'answer': 'poisoning unsuspecting commoners'} \n",
      " \n",
      " contain the element in various compounds, and peddling the item on the same website that calls it dangerous\n",
      "{'score': 0.0002603823086246848, 'start': 1225, 'end': 1238, 'answer': 'death threats'} \n",
      " \n",
      " An Afghan migrant attacked a woman at an asylum centre in Austria because she was reading a bible\n",
      "{'score': 0.0019291667267680168, 'start': 172, 'end': 176, 'answer': '2016'} \n",
      " \n",
      " \"Pirates 5 Release Date Shifted To 2016\"\n",
      "{'score': 0.00023805959790479392, 'start': 469, 'end': 519, 'answer': 'The truth is that Taylor Swift and I are together,'} \n",
      " \n",
      " \"That\\s the truth. It\\s not a publicity stunt.\"\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_qa = df_selected[['postText', 'targetParagraphs', 'spoiler', 'postPlatform']]\n",
    "\n",
    "question_answer_pipeline = pipeline(\"question-answering\", model, tokenizer = \"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "# Question 14 is long as hell\n",
    "\n",
    "correct_spoilers = 0\n",
    "for i in range(15, 25):\n",
    "    question = df_qa.loc[i]['postText']\n",
    "    context = df_qa.loc[i]['targetParagraphs']\n",
    "    answer = df_qa.loc[i]['spoiler']\n",
    "    answer = answer.replace('[', '')\n",
    "    answer = answer.replace(']', '')\n",
    "    answer = answer.replace(\"'\", '')\n",
    "    result = question_answer_pipeline(question = question, context = context)\n",
    "    print(result,\"\\n \\n\", answer)\n",
    "    if(result['answer'] == answer):\n",
    "        print(\"Correct\", question)\n",
    "        correct_spoilers = correct_spoilers+1\n",
    "    #print(result['answer'], answer, \"\\n\")\n",
    "\n",
    "print(correct_spoilers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946ba0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79baf4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd178d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff2d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ce4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5e982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
