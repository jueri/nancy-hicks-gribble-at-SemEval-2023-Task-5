{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52d8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk as nltk\n",
    "import spacy\n",
    "import regex\n",
    "import re\n",
    "import sklearn\n",
    "from nltk import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62226c5",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c2bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"Data/webis-clickbait-22/train.jsonl\"\n",
    "valid_data_path = \"Data/webis-clickbait-22/validation.jsonl\"\n",
    "\n",
    "df = pd.read_json(train_data_path, lines=True)\n",
    "df2 = pd.read_json(valid_data_path, lines = True)\n",
    "df = df.append(df2)\n",
    "df = df.reset_index()\n",
    "df = df.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c623e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553ef47",
   "metadata": {},
   "source": [
    "### Select important columns for analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff090f0",
   "metadata": {},
   "source": [
    "We are using the Posttext, Targetparagraph, spoiler and the postplatform to possibly classify the spoiler type (tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eae57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_selected = df[['postText','targetParagraphs', 'spoiler', 'tags']].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c1044",
   "metadata": {},
   "source": [
    "### Text is cleaned and pre-processed in the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9209dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cae0022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18086b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97623e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df[['postText','targetParagraphs', 'spoiler', 'tags']]\n",
    "\n",
    "    # convert all columns into strings\n",
    "    df[['postText', 'targetParagraphs', 'spoiler', 'tags']] = df[['postText', 'targetParagraphs', 'spoiler', 'tags']].astype(str)\n",
    "    #tokenize the relevant columns (not actually used for the Bag of Word approach)\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    df[\"postText_tokens\"] = df.apply(lambda row: tokenizer.tokenize(row[\"postText\"]), axis = 1)\n",
    "    df[\"paragraph_tokens\"] = df.apply(lambda row: tokenizer.tokenize(row[\"targetParagraphs\"]), axis = 1)\n",
    "    df[\"spoiler_tokens\"] = df.apply(lambda row: tokenizer.tokenize(row[\"spoiler\"]), axis = 1)\n",
    "    \n",
    "    #removing stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    df[\"postText_tokens\"] = df.apply(lambda row: [element for element in row[\"postText_tokens\"] if element not in stopwords], axis = 1)\n",
    "    df[\"paragraph_tokens\"] = df.apply(lambda row: [element for element in row[\"paragraph_tokens\"] if element not in stopwords], axis = 1)\n",
    "    df[\"spoiler_tokens\"] = df.apply(lambda row: [element for element in row[\"spoiler_tokens\"] if element not in stopwords], axis = 1)\n",
    "    \n",
    "    #lowercasing \n",
    "    df['postText_tokens'] = df['postText_tokens'].map(lambda row: list(map(str.lower, row)))\n",
    "    df['paragraph_tokens'] = df['paragraph_tokens'].map(lambda row: list(map(str.lower, row)))\n",
    "    df['spoiler_tokens'] = df['spoiler_tokens'].map(lambda row: list(map(str.lower, row)))\n",
    "    \n",
    "    # multiple space to single space\n",
    "    df[['postText_tokens', 'paragraph_tokens', 'spoiler_tokens']] = df[['postText_tokens', 'paragraph_tokens', 'spoiler_tokens']].replace(r'\\s+', ' ', regex=True)\n",
    "    #special characters\n",
    "    df[['postText_tokens', 'paragraph_tokens', 'spoiler_tokens']] = df[['postText_tokens', 'paragraph_tokens', 'spoiler_tokens']].replace(r'\\W', ' ', regex = True)\n",
    "\n",
    "    #lemmatize tokens\n",
    "    df['postText_tokens'] = df['postText_tokens'].apply(lemmatize_text)\n",
    "    df['paragraph_tokens'] = df['paragraph_tokens'].apply(lemmatize_text)\n",
    "    df['spoiler_tokens'] = df['spoiler_tokens'].apply(lemmatize_text)\n",
    "    \n",
    "    #count column lengths\n",
    "    df['postText_length'] = \"\"\n",
    "    df['paragraph_length'] = \"\"\n",
    "    df['spoiler_length'] = \"\"\n",
    "    for i in range(len(df)):\n",
    "        df['postText_length'][i] = len(df['postText_tokens'][i])\n",
    "        df['paragraph_length'][i] = len(df['paragraph_tokens'][i])\n",
    "        df['spoiler_length'][i] = len(df['spoiler_tokens'][i])\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        questionmark = \"?\"\n",
    "        df['has_questionmark'] = 'posthasquestionmark'\n",
    "        if questionmark in df['postText'][i]:\n",
    "            df['has_questionmark'] = 'posthasnoquestionmark'\n",
    "            \n",
    "            \n",
    "    mean_postText_length = df['postText_length'].mean()\n",
    "    mean_paragraph_length = df['paragraph_length'].mean()\n",
    "    mean_spoiler_length = df['spoiler_length'].mean()\n",
    "\n",
    "    df['postText_length'] = df['postText_length'].apply(lambda x: 'overavg_post_length' if x > mean_postText_length else 'underavg_post_length')\n",
    "    df['paragraph_length'] = df['paragraph_length'].apply(lambda x: 'overavg_paragraph_length' if x > mean_paragraph_length else 'underavg_paragraph_length')\n",
    "    df['spoiler_length'] = df['spoiler_length'].apply(lambda x: 'overavg_spoiler_length' if mean_spoiler_length > 49 else 'underavg_spoiler_length')\n",
    "\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        df['has_numeric'] = any(str.isdigit(c) for c in df['targetParagraphs'][i])\n",
    "    df['has_numeric'] = np.where(df['has_numeric'], 'hasnumeric', 'nonumeric')\n",
    "   \n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    df['Entities'] = df['postText'].apply(lambda sent: [(ent.text, ent.label_) for ent in nlp(sent).ents])  \n",
    "    df['Entities'][0]\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tostring = str(df['Entities'][i])\n",
    "        tostring = ' '.join(str(item) for tup in df['Entities'][i] for item in tup)\n",
    "        df['Entities'][i] = tostring\n",
    "  \n",
    "    df['multi_signs'] = \"\"\n",
    "    multi_signs = ['1.', '2.', '3.', '4.', '5.', '6.','7.', '8,', '9.', '10', 'first', 'second', 'third', 'list']\n",
    "    df['multi_signs'] = df['targetParagraphs'].apply(lambda x: any([k in x for k in multi_signs]))\n",
    "\n",
    "    df['combined_texts'] = \"\"\n",
    "    df['combined_texts'] = df['postText'] + \" \" + df['targetParagraphs'] + \" \" + df['postText_length'] + \" \" + df['paragraph_length'] + \" \" + df['has_questionmark'] + \" \" + df['has_numeric'] + df['Entities']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96c811e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasrehbach/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"postText_tokens\"] = df.apply(lambda row: tokenizer.tokenize(row[\"postText\"]), axis = 1)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"paragraph_tokens\"] = df.apply(lambda row: tokenizer.tokenize(row[\"targetParagraphs\"]), axis = 1)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"spoiler_tokens\"] = df.apply(lambda row: tokenizer.tokenize(row[\"spoiler\"]), axis = 1)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"postText_tokens\"] = df.apply(lambda row: [element for element in row[\"postText_tokens\"] if element not in stopwords], axis = 1)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"paragraph_tokens\"] = df.apply(lambda row: [element for element in row[\"paragraph_tokens\"] if element not in stopwords], axis = 1)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"spoiler_tokens\"] = df.apply(lambda row: [element for element in row[\"spoiler_tokens\"] if element not in stopwords], axis = 1)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['postText_tokens'] = df['postText_tokens'].map(lambda row: list(map(str.lower, row)))\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['paragraph_tokens'] = df['paragraph_tokens'].map(lambda row: list(map(str.lower, row)))\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['spoiler_tokens'] = df['spoiler_tokens'].map(lambda row: list(map(str.lower, row)))\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['postText_tokens'] = df['postText_tokens'].apply(lemmatize_text)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['paragraph_tokens'] = df['paragraph_tokens'].apply(lemmatize_text)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['spoiler_tokens'] = df['spoiler_tokens'].apply(lemmatize_text)\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['postText_length'] = \"\"\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['paragraph_length'] = \"\"\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['spoiler_length'] = \"\"\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['postText_length'][i] = len(df['postText_tokens'][i])\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['paragraph_length'][i] = len(df['paragraph_tokens'][i])\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['spoiler_length'][i] = len(df['spoiler_tokens'][i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['has_questionmark'] = 'posthasquestionmark'\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['has_questionmark'] = 'posthasnoquestionmark'\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['postText_length'] = df['postText_length'].apply(lambda x: 'overavg_post_length' if x > mean_postText_length else 'underavg_post_length')\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['paragraph_length'] = df['paragraph_length'].apply(lambda x: 'overavg_paragraph_length' if x > mean_paragraph_length else 'underavg_paragraph_length')\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['spoiler_length'] = df['spoiler_length'].apply(lambda x: 'overavg_spoiler_length' if mean_spoiler_length > 49 else 'underavg_spoiler_length')\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['has_numeric'] = any(str.isdigit(c) for c in df['targetParagraphs'][i])\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['has_numeric'] = np.where(df['has_numeric'], 'hasnumeric', 'nonumeric')\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Entities'] = df['postText'].apply(lambda sent: [(ent.text, ent.label_) for ent in nlp(sent).ents])\n",
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/1462469078.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Entities'][i] = tostring\n"
     ]
    }
   ],
   "source": [
    "df_selected = preprocess_data(df)\n",
    "#df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f2c21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_selected['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9687fa13",
   "metadata": {},
   "source": [
    "### Convert our text into bag of word vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "686590d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a56a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_features could be used to constrain the amount of words\n",
    "# ngram_range 2,2 is too long\n",
    "#ngram range 1,2 works without tf-idf\n",
    "vectorizer = CountVectorizer(stop_words=stopwords, lowercase=True, tokenizer = tokenizer.tokenize, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c939bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the vectorized dataframes to another and transform them back\n",
    "combined_bow = vectorizer.fit_transform(df_selected['combined_texts']).toarray()\n",
    "bag_of_words = pd.DataFrame(combined_bow, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "590122f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00000000000000000000000000000000000000625</th>\n",
       "      <th>00000000130</th>\n",
       "      <th>000001002003004005006</th>\n",
       "      <th>0000024</th>\n",
       "      <th>00007</th>\n",
       "      <th>0005</th>\n",
       "      <th>000s</th>\n",
       "      <th>...</th>\n",
       "      <th>いいね</th>\n",
       "      <th>コメント</th>\n",
       "      <th>ツ</th>\n",
       "      <th>件</th>\n",
       "      <th>寵物小精靈</th>\n",
       "      <th>比卡超</th>\n",
       "      <th>皮卡丘</th>\n",
       "      <th>神奇寶貝</th>\n",
       "      <th>精靈寶可夢</th>\n",
       "      <th>認証済み</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 62332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  00  000  00000000000000000000000000000000000000625  00000000130  \\\n",
       "0     0   0    0                                          0            0   \n",
       "1     0   0    0                                          0            0   \n",
       "2     0   0    0                                          0            0   \n",
       "3     0   0    0                                          0            0   \n",
       "4     0   0    1                                          0            0   \n",
       "...  ..  ..  ...                                        ...          ...   \n",
       "3995  0   0    0                                          0            0   \n",
       "3996  0   0    0                                          0            0   \n",
       "3997  0   0    0                                          0            0   \n",
       "3998  0   0    0                                          0            0   \n",
       "3999  0   0    0                                          0            0   \n",
       "\n",
       "      000001002003004005006  0000024  00007  0005  000s  ...  いいね  コメント  ツ  件  \\\n",
       "0                         0        0      0     0     0  ...    0     0  0  0   \n",
       "1                         0        0      0     0     0  ...    0     0  0  0   \n",
       "2                         0        0      0     0     0  ...    0     0  0  0   \n",
       "3                         0        0      0     0     0  ...    0     0  0  0   \n",
       "4                         0        0      0     0     0  ...    0     0  0  0   \n",
       "...                     ...      ...    ...   ...   ...  ...  ...   ... .. ..   \n",
       "3995                      0        0      0     0     0  ...    0     0  0  0   \n",
       "3996                      0        0      0     0     0  ...    0     0  0  0   \n",
       "3997                      0        0      0     0     0  ...    0     0  0  0   \n",
       "3998                      0        0      0     0     0  ...    0     0  0  0   \n",
       "3999                      0        0      0     0     0  ...    0     0  0  0   \n",
       "\n",
       "      寵物小精靈  比卡超  皮卡丘  神奇寶貝  精靈寶可夢  認証済み  \n",
       "0         0    0    0     0      0     0  \n",
       "1         0    0    0     0      0     0  \n",
       "2         0    0    0     0      0     0  \n",
       "3         0    0    0     0      0     0  \n",
       "4         0    0    0     0      0     0  \n",
       "...     ...  ...  ...   ...    ...   ...  \n",
       "3995      0    0    0     0      0     0  \n",
       "3996      0    0    0     0      0     0  \n",
       "3997      0    0    0     0      0     0  \n",
       "3998      0    0    0     0      0     0  \n",
       "3999      0    0    0     0      0     0  \n",
       "\n",
       "[4000 rows x 62332 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beaa78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9cb13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f267ccee",
   "metadata": {},
   "source": [
    "### Finding TFIDF of our bag of words\n",
    "\n",
    "(n = 1,2) took over an hour and didnt compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d3314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "801e96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fbbe0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c18b5245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Columns: 62332 entries, 0 to 62331\n",
      "dtypes: float64(62332)\n",
      "memory usage: 1.9 GB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07cdd6f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>62322</th>\n",
       "      <th>62323</th>\n",
       "      <th>62324</th>\n",
       "      <th>62325</th>\n",
       "      <th>62326</th>\n",
       "      <th>62327</th>\n",
       "      <th>62328</th>\n",
       "      <th>62329</th>\n",
       "      <th>62330</th>\n",
       "      <th>62331</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 62332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1         2      3      4      5      6      7      8      9      \\\n",
       "0       0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1       0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2       0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3       0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4       0.0    0.0  0.014798    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...     ...    ...       ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3995    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3996    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3997    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3998    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3999    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ...  62322  62323  62324  62325  62326  62327  62328  62329  62330  \\\n",
       "0     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3995  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3996  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3997  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3998  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3999  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      62331  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "3995    0.0  \n",
       "3996    0.0  \n",
       "3997    0.0  \n",
       "3998    0.0  \n",
       "3999    0.0  \n",
       "\n",
       "[4000 rows x 62332 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c274a75",
   "metadata": {},
   "source": [
    "## Using the saved Logistic Regression for spoiler classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1de3e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)\n",
    "y = pd.get_dummies(y['tags'])\n",
    "y = y.values.argmax(1)\n",
    "y = pd.DataFrame(y)\n",
    "y = y.rename(columns={0: \"tags\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d0c81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fbb9804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model back from file\n",
    "PKl_Filename = 'Pickle_LR_Model.pkl'\n",
    "with open(PKl_Filename, 'rb') as file:  \n",
    "    Pickled_LR_Model = pickle.load(file)\n",
    "\n",
    "Pickled_LR_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89b9cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasrehbach/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23  59  61]\n",
      " [  7 178 120]\n",
      " [  2 114 236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.16      0.26       143\n",
      "           1       0.51      0.58      0.54       305\n",
      "           2       0.57      0.67      0.61       352\n",
      "\n",
      "    accuracy                           0.55       800\n",
      "   macro avg       0.60      0.47      0.47       800\n",
      "weighted avg       0.57      0.55      0.52       800\n",
      "\n",
      "0.54625\n"
     ]
    }
   ],
   "source": [
    "Pickled_LR_Model.fit(X_train, y_train)\n",
    "y_pred = Pickled_LR_Model.predict(X_test)\n",
    "y_pred_proba = Pickled_LR_Model.predict_proba(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736fb2c",
   "metadata": {},
   "source": [
    "### Apply ML techniques\n",
    "\n",
    "Random Forest and Logistic Regression were the most successful approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a9b0b4",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c376fad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/33g3tqwn4c59qnzswhnf6ry00000gn/T/ipykernel_53122/2488286459.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=100, n_estimators=500, random_state=8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=500, random_state=8, max_depth=100)\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e73783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d4feb6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16  60  67]\n",
      " [  4 189 112]\n",
      " [  3 123 226]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.11      0.19       143\n",
      "           1       0.51      0.62      0.56       305\n",
      "           2       0.56      0.64      0.60       352\n",
      "\n",
      "    accuracy                           0.54       800\n",
      "   macro avg       0.59      0.46      0.45       800\n",
      "weighted avg       0.56      0.54      0.51       800\n",
      "\n",
      "0.53875\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1598a3c3",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a45dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasrehbach/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c50a6a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_proba = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b859f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23  59  61]\n",
      " [  7 178 120]\n",
      " [  2 114 236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.16      0.26       143\n",
      "           1       0.51      0.58      0.54       305\n",
      "           2       0.57      0.67      0.61       352\n",
      "\n",
      "    accuracy                           0.55       800\n",
      "   macro avg       0.60      0.47      0.47       800\n",
      "weighted avg       0.57      0.55      0.52       800\n",
      "\n",
      "0.54625\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb90c729",
   "metadata": {},
   "source": [
    "## Saving the best model as pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d8394c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to file in the current working directory\n",
    "\n",
    "Pkl_Filename = \"Pickle_LR_Model.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(logreg, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc135a0",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63a7ff4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasrehbach/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27d96506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34  57  52]\n",
      " [ 61 129 115]\n",
      " [ 77 123 152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.24      0.22       143\n",
      "           1       0.42      0.42      0.42       305\n",
      "           2       0.48      0.43      0.45       352\n",
      "\n",
      "    accuracy                           0.39       800\n",
      "   macro avg       0.36      0.36      0.36       800\n",
      "weighted avg       0.40      0.39      0.40       800\n",
      "\n",
      "0.39375\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae49dac",
   "metadata": {},
   "source": [
    "### XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00618d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1387ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8985c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \"objective\": \"multi:softmax\", 'num_class': 3, 'max_depth' : 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e64f3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(X_train, y_train)\n",
    "d_test = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c319a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.train(params, d_train, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dea5f2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 41  51  51]\n",
      " [ 12 179 114]\n",
      " [ 22 135 195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.29      0.38       143\n",
      "           1       0.49      0.59      0.53       305\n",
      "           2       0.54      0.55      0.55       352\n",
      "\n",
      "    accuracy                           0.52       800\n",
      "   macro avg       0.53      0.48      0.49       800\n",
      "weighted avg       0.52      0.52      0.51       800\n",
      "\n",
      "0.51875\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(d_test)\n",
    "#y_pred = np.where(np.array(y_pred) > 0.5, 1, 0)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65444fed",
   "metadata": {},
   "source": [
    "### KNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d8f338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c775b91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasrehbach/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7a160a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 70  37  36]\n",
      " [ 88 121  96]\n",
      " [ 93 111 148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.49      0.36       143\n",
      "           1       0.45      0.40      0.42       305\n",
      "           2       0.53      0.42      0.47       352\n",
      "\n",
      "    accuracy                           0.42       800\n",
      "   macro avg       0.42      0.44      0.42       800\n",
      "weighted avg       0.45      0.42      0.43       800\n",
      "\n",
      "0.42375\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
