{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Sentence Classifyer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(fields: List[str], files: Dict[str, str], mapping: Dict[str, int]) -> pd.DataFrame:\n",
    "    dataset = {}\n",
    "    \n",
    "    def encode_label(label: str):\n",
    "        return mapping[label]\n",
    "\n",
    "    def load_data(file: str):\n",
    "        df = pd.read_json(file, lines=True)\n",
    "\n",
    "        data = []\n",
    "        for _, i in df.iterrows():\n",
    "            text = \"\"\n",
    "            for field in fields:\n",
    "                if isinstance(i[field], list):\n",
    "                    text += ' '.join(i[field])\n",
    "                elif isinstance(field, str):\n",
    "                    text += i[field]\n",
    "                else:\n",
    "                    raise NotImplemented\n",
    "\n",
    "            data.append({\n",
    "                \"text\": text,\n",
    "                \"label\": encode_label(i[\"tags\"][0])})\n",
    "        return data\n",
    "\n",
    "\n",
    "    for split in list(files.keys()):\n",
    "        dataset[split] = load_data(files[split])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields=[\"postText\", \"targetTitle\", \"targetParagraphs\"]\n",
    "dataset = load_dataset(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text[\"text\"]for text in dataset[\"validation\"]]\n",
    "text = texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Multi model prediction\n",
    "checkpoint = \"path to model\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "mapping = {0: 'passage', 1: 'phrase', 2: 'multi'}\n",
    "\n",
    "def predict_one(text, model):\n",
    "    tokenized = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokenized).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return mapping[predicted_class_id]\n",
    "\n",
    "predicted_tag = predict_one(text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "\n",
    "def load_input(df):\n",
    "    if type(df) != pd.DataFrame:\n",
    "        df = pd.read_json(df, lines=True)\n",
    "    \n",
    "    ret = []\n",
    "    for _, i in df.iterrows():\n",
    "        ret += [{'text': ' '.join(i['postText']) + ' - ' + i['targetTitle'] + ' ' + ' '.join(i['targetParagraphs']), 'uuid': i['uuid']}]\n",
    "    \n",
    "    return pd.DataFrame(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/jueri/dev/ANLP2223/Data/webis-clickbait-22/train.jsonl\"\n",
    "df = load_input(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>0af11f6b-c889-4520-9372-66ba25cb7657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NASA sets date for full recovery of ozone hole...</td>\n",
       "      <td>b1a1f63d-8853-4a11-89e8-6b2952a393ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is what makes employees happy -- and it's...</td>\n",
       "      <td>008b7b19-0445-4e16-8f9e-075b73f80ca4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Passion is overrated — 7 work habits you need ...</td>\n",
       "      <td>31ecf93c-3e21-4c80-949b-aa549a046b93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The perfect way to cook rice so that it's perf...</td>\n",
       "      <td>31b108a3-c828-421a-a4b9-cf651e9ac859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>Has Facebook's video explosion completely shak...</td>\n",
       "      <td>92578045-699f-4957-a3c5-cff2c3874dae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>Cop Is Eating At A Chili's When Teen Hands Him...</td>\n",
       "      <td>51682121-df0b-4289-a95f-e1bc3d181306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>5 popular myths about visible signs of aging t...</td>\n",
       "      <td>9c45ca67-38c4-47b4-aa0d-48434bae09fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>You need to see this Twitter account that pred...</td>\n",
       "      <td>9d05984c-3920-47c0-aa97-8df58cca1fec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>GOP congressman comes out for gay marriage - P...</td>\n",
       "      <td>0d9e3a31-77f7-414a-9d70-5213f2c0cd94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1     NASA sets date for full recovery of ozone hole...   \n",
       "2     This is what makes employees happy -- and it's...   \n",
       "3     Passion is overrated — 7 work habits you need ...   \n",
       "4     The perfect way to cook rice so that it's perf...   \n",
       "...                                                 ...   \n",
       "3195  Has Facebook's video explosion completely shak...   \n",
       "3196  Cop Is Eating At A Chili's When Teen Hands Him...   \n",
       "3197  5 popular myths about visible signs of aging t...   \n",
       "3198  You need to see this Twitter account that pred...   \n",
       "3199  GOP congressman comes out for gay marriage - P...   \n",
       "\n",
       "                                      uuid  \n",
       "0     0af11f6b-c889-4520-9372-66ba25cb7657  \n",
       "1     b1a1f63d-8853-4a11-89e8-6b2952a393ec  \n",
       "2     008b7b19-0445-4e16-8f9e-075b73f80ca4  \n",
       "3     31ecf93c-3e21-4c80-949b-aa549a046b93  \n",
       "4     31b108a3-c828-421a-a4b9-cf651e9ac859  \n",
       "...                                    ...  \n",
       "3195  92578045-699f-4957-a3c5-cff2c3874dae  \n",
       "3196  51682121-df0b-4289-a95f-e1bc3d181306  \n",
       "3197  9c45ca67-38c4-47b4-aa0d-48434bae09fc  \n",
       "3198  9d05984c-3920-47c0-aa97-8df58cca1fec  \n",
       "3199  0d9e3a31-77f7-414a-9d70-5213f2c0cd94  \n",
       "\n",
       "[3200 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(texts)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one vs rest prediction\n",
    "checkpoint = {\"passage\": \"path to model\", \"phrase\": \"path to model\", \"multi\": \"path to model\"}\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint[\"passage\"])\n",
    "models = {\n",
    "    \"passage\": AutoModelForSequenceClassification.from_pretrained(checkpoint[\"passage\"], num_labels=2),\n",
    "    \"phrase\": AutoModelForSequenceClassification.from_pretrained(checkpoint[\"phrase\"], num_labels=2),\n",
    "    \"multi\": AutoModelForSequenceClassification.from_pretrained(checkpoint[\"multi\"], num_labels=2)\n",
    "}\n",
    "\n",
    "def predict_one_multi(text, model):\n",
    "    def predict_probability(text, model):\n",
    "        tokenized = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            logits = model(**tokenized).logits\n",
    "        return logits.argmax()\n",
    "\n",
    "\n",
    "    probabilities = {}\n",
    "    for tag_name, model in models.items():\n",
    "        probability = predict_probability(text, model)\n",
    "        probabilities[tag_name] = probability\n",
    "\n",
    "    return max(probabilities, key=probabilities.get)\n",
    "\n",
    "\n",
    "predicted_tag = predict_one_multi(text, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"postText\": [[1,2,3], 2, 3], \"targetTitle\": [4, 5, 6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>targetTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    postText  targetTitle\n",
       "0  [1, 2, 3]            4\n",
       "1          2            5\n",
       "2          3            6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "0    2\n",
       "0    3\n",
       "1    2\n",
       "2    3\n",
       "Name: postText, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.postText.explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, i in df.iterrows():\n",
    "    i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only join an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m field \u001b[39min\u001b[39;00m  [\u001b[39m'\u001b[39m\u001b[39mpostText\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtargetTitle\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     text\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(i[field])\n",
      "\u001b[0;31mTypeError\u001b[0m: can only join an iterable"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "for field in  ['postText', 'targetTitle']:\n",
    "    text+=\"\".join(i[field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://drive.google.com/drive/folders/11_SX2tCrCm1w4_4-vwJGW6LnvS8RHjSV?usp=share_link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ANLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 21 2022, 23:50:54) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a963ddbb9d4d2ccdf936f46bc94ee37518f3a93a08eb4602276258409c4ce148"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
